# CEP Crawler - Sistema AssÃ­ncrono de Processamento de CEPs

Sistema backend em Node.js/TypeScript que processa intervalos de CEPs de forma assÃ­ncrona utilizando fila de mensagens (ElasticMQ), workers em background, MongoDB para persistÃªncia e Docker para orquestraÃ§Ã£o.

## ğŸ¯ CaracterÃ­sticas

- âœ… Processamento assÃ­ncrono de CEPs via fila de mensagens
- âœ… Workers independentes com controle de concorrÃªncia
- âœ… Retry automÃ¡tico com Dead Letter Queue (DLQ)
- âœ… Rate limiting para nÃ£o sobrecarregar a API ViaCEP
- âœ… PersistÃªncia de dados em MongoDB
- âœ… API REST para iniciar processamento e consultar status
- âœ… OrquestraÃ§Ã£o completa via Docker Compose
- âœ… Logs claros de processamento

## ğŸ§© CaracterÃ­sticas da Codebase

- **Cache com Redis:** Implementado para otimizar consultas repetidas ao ViaCEP, com TTL configurÃ¡vel para dados e erros (404).
- **Dashboard e MÃ©tricas:** Endpoint `/cep/dashboard/summary` para dados consolidados e `/metrics` expondo mÃ©tricas no formato Prometheus.
- **Testes Automatizados:** Testes unitÃ¡rios e de integraÃ§Ã£o configurados com Jest.
- **CI/CD Pipeline:** ConfiguraÃ§Ã£o de integraÃ§Ã£o contÃ­nua presente.
- **Rate Limiting na API:** ProteÃ§Ã£o contra sobrecarga implementada com `express-rate-limit`.
- **Webhooks:** Sistema de notificaÃ§Ã£o via HTTP POST disparado automaticamente ao finalizar um crawl.

## ğŸ“ Conceitos Implementados

### Arquitetura AssÃ­ncrona

- **Non-blocking API:** Responde imediatamente sem aguardar processamento
- **Message Queue:** Desacoplamento entre produtor e consumidor
- **Background Workers:** Processamento independente e escalÃ¡vel

### Confiabilidade

- **Retry Logic:** Tentativas automÃ¡ticas em caso de falha
- **Dead Letter Queue:** Isolamento de mensagens problemÃ¡ticas
- **Graceful Shutdown:** Encerramento controlado dos serviÃ§os
- **Health Checks:** VerificaÃ§Ã£o de disponibilidade dos serviÃ§os

### Performance

- **ConcorrÃªncia Controlada:** Processamento paralelo com limites
- **Rate Limiting:** Respeito aos limites da API externa
- **Batch Processing:** Envio de mensagens em lote
- **Ãndices MongoDB:** Consultas otimizadas

### Escalabilidade

- **Horizontal Scaling:** MÃºltiplos workers podem ser adicionados
- **Stateless Workers:** NÃ£o mantÃ©m estado entre processamentos
- **Queue-based:** Fila distribui trabalho automaticamente

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ POST /cep/crawl
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API (Node.js) â”‚â”€â”€â”€â–º Cria crawl no MongoDB
â”‚   Express       â”‚â”€â”€â”€â–º Enfileira CEPs no SQS
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ElasticMQ     â”‚
â”‚   (SQS-like)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Workers (x2)   â”‚â”€â”€â”€â–º Consome mensagens
â”‚  Node.js        â”‚â”€â”€â”€â–º Consulta ViaCEP
â”‚  Background     â”‚â”€â”€â”€â–º Salva resultados
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”€â”€â”€â–º Atualiza contadores
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MongoDB      â”‚
â”‚  - crawls       â”‚
â”‚  - cep_results  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos

- Docker e Docker Compose instalados
- Porta 3000 (API), 27017 (MongoDB), 9324 (ElasticMQ) disponÃ­veis

### InstalaÃ§Ã£o e ExecuÃ§Ã£o

1. **Clone e configure o ambiente:**

```bash
cd crawler
cp .env.example .env
```

2. **Inicie todos os serviÃ§os com Docker Compose:**

```bash
docker-compose up --build
```

Isso irÃ¡ subir:
- API HTTP na porta 3000
- MongoDB na porta 27017
- ElasticMQ na porta 9324
- 2 Workers processando em background

3. **Aguarde os serviÃ§os ficarem prontos:**

```
âœ… MongoDB healthy
âœ… ElasticMQ healthy
âœ… API iniciada
âœ… Workers iniciados
```

## ğŸ“¡ API Endpoints

### 1. Iniciar Processamento de CEPs

**POST** `/cep/crawl`

```bash
curl -X POST http://localhost:3000/cep/crawl \
  -H "Content-Type: application/json" \
  -d '{
    "cep_start": "01001000",
    "cep_end": "01002000"
  }'
```

**Response (202 Accepted):**
```json
{
  "crawl_id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "pending",
  "total": 1001
}
```

### 2. Consultar Status do Processamento

**GET** `/cep/crawl/:crawl_id`

```bash
curl http://localhost:3000/cep/crawl/123e4567-e89b-12d3-a456-426614174000
```

**Response (200 OK):**
```json
{
  "crawl_id": "123e4567-e89b-12d3-a456-426614174000",
  "status": "running",
  "total": 1001,
  "processed": 650,
  "success": 620,
  "error": 30,
  "created_at": "2025-12-29T10:00:00.000Z",
  "updated_at": "2025-12-29T10:05:30.000Z"
}
```

**Status possÃ­veis:**
- `pending` - Aguardando inÃ­cio do processamento
- `running` - Em processamento
- `finished` - ConcluÃ­do
- `failed` - Falhou

### 3. Consultar Resultados (Paginado)

**GET** `/cep/crawl/:crawl_id/results?page=1&limit=50`

```bash
curl "http://localhost:3000/cep/crawl/123e4567-e89b-12d3-a456-426614174000/results?page=1&limit=50"
```

**Response (200 OK):**
```json
{
  "crawl_id": "123e4567-e89b-12d3-a456-426614174000",
  "page": 1,
  "limit": 50,
  "total": 1001,
  "total_pages": 21,
  "data": [
    {
      "_id": "...",
      "crawl_id": "123e4567-e89b-12d3-a456-426614174000",
      "cep": "01001000",
      "status": "success",
      "data": {
        "cep": "01001-000",
        "logradouro": "PraÃ§a da SÃ©",
        "bairro": "SÃ©",
        "localidade": "SÃ£o Paulo",
        "uf": "SP",
        ...
      },
      "error_message": null,
      "processed_at": "2025-12-29T10:02:15.000Z"
    },
    ...
  ]
}
```

### 4. Health Check

**GET** `/health`

```bash
curl http://localhost:3000/health
```

**Response (200 OK):**
```json
{
  "status": "ok",
  "timestamp": "2025-12-29T10:00:00.000Z"
}
```

### 5. Dashboard (Resumo para UI)

**GET** `/cep/dashboard/summary`

Retorna contagens por status, agregados de sucesso/erro e Ãºltimos crawls para alimentar um frontend.

### 6. MÃ©tricas Prometheus

**GET** `/metrics`

ExposiÃ§Ã£o em formato Prometheus com mÃ©tricas HTTP e de runtime.

## ğŸ—„ï¸ Modelagem de Dados

### Collection: `crawls`

```typescript
{
  "_id": "uuid",
  "cep_start": "01001000",
  "cep_end": "01002000",
  "status": "pending | running | finished | failed",
  "total": 1001,
  "processed": 650,
  "success": 620,
  "error": 30,
  "created_at": ISODate,
  "updated_at": ISODate
}
```

### Collection: `cep_results`

```typescript
{
  "_id": "ObjectId",
  "crawl_id": "uuid",
  "cep": "01001000",
  "status": "success | error",
  "data": {
    "cep": "01001-000",
    "logradouro": "...",
    "bairro": "...",
    ...
  },
  "error_message": null,
  "processed_at": ISODate
}
```

## âš™ï¸ ConfiguraÃ§Ã£o

Principais variÃ¡veis de ambiente (`.env`):

```bash
# API
PORT=3000

# MongoDB
MONGODB_URI=mongodb://mongodb:27017/cep_crawler

# SQS / ElasticMQ
AWS_REGION=us-east-1
SQS_ENDPOINT=http://elasticmq:9324
SQS_QUEUE_URL=http://elasticmq:9324/000000000000/cep-queue

# Redis Cache
REDIS_URL=redis://redis:6379
REDIS_TTL_SECONDS=86400
REDIS_NULL_TTL_SECONDS=600

# Worker
WORKER_CONCURRENCY=10          # Mensagens simultÃ¢neas
WORKER_MAX_RETRIES=3           # Tentativas antes de falha definitiva
WORKER_RETRY_DELAY_MS=1000     # Delay entre retries
VIACEP_RATE_LIMIT=10           # RequisiÃ§Ãµes/segundo por worker

# API
API_RATE_LIMIT_WINDOW_MS=60000 # Janela de rate limit
API_RATE_LIMIT_MAX=200         # RequisiÃ§Ãµes por janela

# Webhooks (opcional)
WEBHOOK_URLS=https://exemplo.com/webhook1,https://exemplo.com/webhook2
```

## ğŸ”„ Funcionamento do Sistema

### Fluxo de Processamento

1. **Cliente envia POST** `/cep/crawl` com range de CEPs
2. **API valida** o range e cria um `crawl_id` Ãºnico
3. **API calcula** todos os CEPs do intervalo
4. **API cria** registro no MongoDB com status `pending`
5. **API enfileira** cada CEP como mensagem no SQS (em batches de 10)
6. **API responde** imediatamente com `202 Accepted`
7. **Workers** consomem mensagens da fila (10 simultÃ¢neas)
8. **Workers** consultam ViaCEP com rate limiting
9. **Workers** salvam resultados no MongoDB
10. **Workers** atualizam contadores do crawl
11. **Workers** deletam mensagem da fila apÃ³s sucesso
12. **Crawl** muda para `finished` quando todos os CEPs sÃ£o processados

### Tratamento de Erros e Retry

- **Retry AutomÃ¡tico:** AtÃ© 3 tentativas por CEP
- **Exponential Backoff:** Delay de 1s entre tentativas
- **Dead Letter Queue:** Mensagens com falha definitiva vÃ£o para DLQ
- **Erros TemporÃ¡rios:** Worker retenta automaticamente
- **Erros Permanentes:** CEP marcado como erro apÃ³s 3 tentativas

### Controle de ConcorrÃªncia

- **API:** NÃ£o bloqueia - responde imediatamente
- **Workers:** 2 instÃ¢ncias processando em paralelo
- **Por Worker:** 10 mensagens simultÃ¢neas
- **Rate Limit:** 10 requisiÃ§Ãµes/segundo ao ViaCEP por worker

## ğŸ§ª Testando o Sistema

### Teste BÃ¡sico (Range Pequeno)

```bash
# Iniciar crawl de 10 CEPs
curl -X POST http://localhost:3000/cep/crawl \
  -H "Content-Type: application/json" \
  -d '{"cep_start": "01001000", "cep_end": "01001009"}'

# Resposta: {"crawl_id": "...", "status": "pending", "total": 10}

# Aguardar alguns segundos e consultar status
curl http://localhost:3000/cep/crawl/{crawl_id}

# Ver resultados
curl "http://localhost:3000/cep/crawl/{crawl_id}/results?page=1&limit=10"
```

### Teste de Carga (Range Maior)

```bash
# 1000 CEPs
curl -X POST http://localhost:3000/cep/crawl \
  -H "Content-Type: application/json" \
  -d '{"cep_start": "01001000", "cep_end": "01001999"}'
```

### Monitorar Logs

```bash
# Ver logs de todos os serviÃ§os
docker-compose logs -f

# Ver apenas logs dos workers
docker-compose logs -f worker

# Ver apenas logs da API
docker-compose logs -f api
```

## ğŸ“Š Monitoramento

### Verificar Fila (ElasticMQ)

```bash
# Acessar interface web do ElasticMQ
curl http://localhost:9325/

# Ver estatÃ­sticas das filas
```

### Consultar MongoDB Diretamente

```bash
# Conectar ao MongoDB
docker exec -it cep-mongodb mongosh cep_crawler

# Ver crawls
db.crawls.find().pretty()

# Ver resultados
db.cep_results.find().limit(10).pretty()

# Contar resultados por status
db.cep_results.aggregate([
  {$group: {_id: "$status", count: {$sum: 1}}}
])
```

## ğŸ› ï¸ Desenvolvimento Local

### Rodar sem Docker

1. **Instalar dependÃªncias:**

```bash
npm install
```

2. **Configurar `.env` para serviÃ§os locais:**

```bash
MONGODB_URI=mongodb://localhost:27017/cep_crawler
SQS_ENDPOINT=http://localhost:9324
```

3. **Rodar API em modo dev:**

```bash
npm run dev
```

4. **Rodar Worker em modo dev (outro terminal):**

```bash
npm run worker
```

### Build TypeScript

```bash
npm run build
```

### Linting e FormataÃ§Ã£o

```bash
npm run lint
npm run format
```

## ğŸ³ Docker Commands

```bash
# Subir todos os serviÃ§os
docker-compose up -d

# Reconstruir imagens
docker-compose up --build

# Ver logs
docker-compose logs -f

# Parar serviÃ§os
docker-compose down

# Parar e limpar volumes
docker-compose down -v

# Escalar workers (4 instÃ¢ncias)
docker-compose up -d --scale worker=4
```

## ğŸ“ Estrutura do Projeto

```
crawler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ database.ts        # ConfiguraÃ§Ã£o MongoDB
â”‚   â”‚   â””â”€â”€ queue.ts           # ConfiguraÃ§Ã£o SQS
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â””â”€â”€ CepController.ts   # Controladores da API
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Crawl.ts           # Modelo de Crawl
â”‚   â”‚   â””â”€â”€ CepResult.ts       # Modelo de Resultado
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”œâ”€â”€ CrawlRepository.ts
â”‚   â”‚   â””â”€â”€ CepResultRepository.ts
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â”œâ”€â”€ types.ts           # Tipos de mensagens
â”‚   â”‚   â”œâ”€â”€ producer.ts        # Produtor de mensagens
â”‚   â”‚   â””â”€â”€ consumer.ts        # Consumidor de mensagens
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ cepRoutes.ts       # Rotas da API
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ CrawlService.ts    # LÃ³gica de negÃ³cio
â”‚   â”‚   â””â”€â”€ ViaCepService.ts   # Cliente ViaCEP
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ cepUtils.ts        # UtilitÃ¡rios de CEP
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â””â”€â”€ cepWorker.ts       # Worker assÃ­ncrono
â”‚   â””â”€â”€ index.ts               # Entry point da API
â”œâ”€â”€ docker-compose.yml         # OrquestraÃ§Ã£o Docker
â”œâ”€â”€ Dockerfile.api             # Imagem Docker da API
â”œâ”€â”€ Dockerfile.worker          # Imagem Docker do Worker
â”œâ”€â”€ elasticmq.conf             # ConfiguraÃ§Ã£o ElasticMQ
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## ğŸ“„ LicenÃ§a

MIT

## ğŸ‘¤ Autor

Sistema desenvolvido como demonstraÃ§Ã£o de arquitetura assÃ­ncrona com Node.js, TypeScript, Message Queue e MongoDB.
